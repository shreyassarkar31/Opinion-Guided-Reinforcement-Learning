{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Policy Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import gymnasium as gym\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "map_size = '8x8'; slippery = False; training_lr = 0.9; advice_lr = 0.9; gamma = 1\n",
    "env = gym.make('FrozenLake-v1', map_name = map_size, is_slippery = slippery)\n",
    "num_states = env.observation_space.n\n",
    "num_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy_Grad(nn.Module):\n",
    "    def __init__(self, num_states, num_actions, hidden_1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(num_states, hidden_1)\n",
    "        self.act1 = nn.ReLU()\n",
    "\n",
    "        self.out = nn.Linear(hidden_1, num_actions)\n",
    "        self.act_output = nn.Softmax(dim = 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.fc1(x))\n",
    "        x = self.act_output(self.out(x))\n",
    "        return x\n",
    "    \n",
    "model = Policy_Grad(num_states, num_actions, num_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_tensor(state):\n",
    "    state_tensor = torch.zeros(num_states, dtype = torch.float32)\n",
    "    state_tensor[state] = 1\n",
    "    return state_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_return(rewards: list, gamma):\n",
    "    # https://stackoverflow.com/questions/65233426/discount-reward-in-reinforce-deep-reinforcement-learning-algorithm\n",
    "    ep_rewards = np.asarray(rewards)\n",
    "    t_steps = np.arange(ep_rewards.size)\n",
    "    ep_returns = ep_rewards * gamma**t_steps\n",
    "    ep_returns = ep_returns[::-1].cumsum()[::-1] / gamma**t_steps\n",
    "    return ep_returns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_network(ep_states, ep_acti