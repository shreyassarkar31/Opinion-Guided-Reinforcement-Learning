A framework for human-informed reinforcement learning by subjective logic

[![License](https://img.shields.io/badge/license-GPL--3.0-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)
[![Unit tests](https://github.com/dagenaik/Uncertainty-in-Reinforcement-Learning/actions/workflows/ci.yaml/badge.svg)](https://github.com/dagenaik/Uncertainty-in-Reinforcement-Learning/actions/workflows/ci.yaml)


# Repository structure

- [/input](https://github.com/dagenaik/Uncertainty-in-Reinforcement-Learning/tree/main/input) - Input files: maps and human advice
- [/src](https://github.com/dagenaik/Uncertainty-in-Reinforcement-Learning/tree/main/src) - Source code
  - Main
    - `runner.py` - Main module
    - `model.py` - Model classes
  - Advice/SL modules
    - `advice_parser.py` - Parses human input from `/input`. Input file naming convention: `advice-[SIZE]x[SIZE]-seed[SEED].txt` Format:
      ```
      grid size [1]
      advice [*]
      ```
    - `sl.py` - Subjective logic utilities
  - Map module
    - `map_tools.py` - Generator, renderer, and parser for maps. Saves maps under `/files` as `.xslx` files.
- [/tests](https://github.com/dagenaik/Uncertainty-in-Reinforcement-Learning/tree/main/tests) - Unit tests.
- [/expsetup](https://github.com/dagenaik/Uncertainty-in-Reinforcement-Learning/tree/main/expsetup) - Input files to the experiments.

# Setup guide
- Clone this repository.
- Install requirements via ```pip install -r requirements.txt```.

# How to use
:warning: All scripts to be run from the root directory. :warning:

- Generate a map by running `python .\src\map_tools.py (--generate --render --size [SIZE] --seed [SEED]) | -default` -- Replace `[SIZE]` and `[SEED]` with the values (int) you need. The `--render` flag is optional. When run with the `-default` option, the default 4x4 map will be generated.
- Create all four advice files with the following name: `advice-[SIZE]x[SIZE]-seed[SEED]-[QUOTA].txt` (e.g., `advice-6x6-seed10-all.txt`). Quota = {'all', 'holes', 'human10', 'human5'}.
- The advice file can be generated by running `python .\src\advice_tools.py --size [SIZE] --seed [SEED] -g [ALL|HOLES]`. `ALL` will generate advice for all cells; `HOLES` will generate advice for the holes and the goal. Advice values for frozen tiles in `ALL`: +1 if no neighboring holes; 0 if one neighboring hole; -1 otherwise.
- Run the experiment using `python .\src\runner.py`.
  Mandatory parameter:
  - `--mode [MODE]` -- The `[MODE]` value is one of the following: `random`, `noadvice`, `synthetic`.
  Optional parameters:
  - `--log [LOG_LEVEL]` -- The `[LOG_LEVEL]` value is one of the following: `critical`, `error`, `warn`, `warning`, `info`, `debug`.
  - `--name [STRING]` -- The name of the experiment based on which the top results folder will be named. If not provided, the folder is named as datetime.now() by formatted as "%Y%m%d-%H%M%S".
- Settings (size, seed, numexperiments, maxepisodes) can be set in `runner.__name__`.
- Results will be generated into `/experiments`, under a timestamped folder, with the following folder structure:
  ```
  - [maxepisodes1]
    - random
      - One .csv file named after the map size and seed.
    - noadvice
      - One .csv file named after the map size and seed.
    - advice-synthetic-[quota]
      - Multiple .csv files named after the map size, seed, and the _u_ parameter used in the specific experiment.
  - [maxepisodes2]
    - ...
  ```
## Analysis and plotting
 - Run `python .\src\analysis.py -a [METHOD_NAME] -s [True|False] -log [LOG_LEVEL]`.
